{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('data/train.csv').drop('id', axis=1).to_numpy()\n",
    "test_raw = pd.read_csv('data/test.csv', dtype=float)\n",
    "split = int(train_raw.shape[0] * .6)\n",
    "X_train = train_raw[:split, :14]\n",
    "y_train = train_raw[:split, 14:]\n",
    "X_valid = train_raw[split:, :14]\n",
    "y_valid = train_raw[split:, 14:]\n",
    "X_valid, X_test = np.array_split(X_valid, 2)\n",
    "y_valid, y_test = np.array_split(y_valid, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# sample size, time steps, input dimension\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], X_valid.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1407/1407 [==============================] - 9s 4ms/step - loss: 0.9827 - val_loss: 0.5317\n",
      "Epoch 2/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5359 - val_loss: 0.5249\n",
      "Epoch 3/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5344 - val_loss: 0.5251\n",
      "Epoch 4/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5322 - val_loss: 0.5205\n",
      "Epoch 5/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5279 - val_loss: 0.5305\n",
      "Epoch 6/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5277 - val_loss: 0.5160\n",
      "Epoch 7/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5247 - val_loss: 0.5148\n",
      "Epoch 8/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5219 - val_loss: 0.5171\n",
      "Epoch 9/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5214 - val_loss: 0.5218\n",
      "Epoch 10/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5194 - val_loss: 0.5206\n",
      "Epoch 11/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5175 - val_loss: 0.5126\n",
      "Epoch 12/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5175 - val_loss: 0.5141\n",
      "Epoch 13/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5154 - val_loss: 0.5110\n",
      "Epoch 14/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5147 - val_loss: 0.5117\n",
      "Epoch 15/60\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5134 - val_loss: 0.5213\n",
      "Epoch 16/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5125 - val_loss: 0.5103\n",
      "Epoch 17/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5113 - val_loss: 0.5148\n",
      "Epoch 18/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5105 - val_loss: 0.5100\n",
      "Epoch 19/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5093 - val_loss: 0.5103\n",
      "Epoch 20/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5083 - val_loss: 0.5090\n",
      "Epoch 21/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5075 - val_loss: 0.5091\n",
      "Epoch 22/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5071 - val_loss: 0.5092\n",
      "Epoch 23/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5067 - val_loss: 0.5079\n",
      "Epoch 24/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5059 - val_loss: 0.5092\n",
      "Epoch 25/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5048 - val_loss: 0.5087\n",
      "Epoch 26/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5045 - val_loss: 0.5091\n",
      "Epoch 27/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5038 - val_loss: 0.5085\n",
      "Epoch 28/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5033 - val_loss: 0.5086\n",
      "Epoch 29/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5024 - val_loss: 0.5067\n",
      "Epoch 30/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5020 - val_loss: 0.5101\n",
      "Epoch 31/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5016 - val_loss: 0.5078\n",
      "Epoch 32/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5011 - val_loss: 0.5127\n",
      "Epoch 33/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5000 - val_loss: 0.5055\n",
      "Epoch 34/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4999 - val_loss: 0.5086\n",
      "Epoch 35/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4995 - val_loss: 0.5060\n",
      "Epoch 36/60\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4988 - val_loss: 0.5091\n",
      "Epoch 37/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4983 - val_loss: 0.5134\n",
      "Epoch 38/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4978 - val_loss: 0.5072\n",
      "Epoch 39/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4970 - val_loss: 0.5068\n",
      "Epoch 40/60\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4966 - val_loss: 0.5086\n",
      "Epoch 41/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4966 - val_loss: 0.5158\n",
      "Epoch 42/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4959 - val_loss: 0.5081\n",
      "Epoch 43/60\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4952 - val_loss: 0.5083\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x23d810b55b0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(128, kernel_size=7, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    keras.layers.Conv1D(256, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPool1D(pool_size=3),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(48, activation='elu'),\n",
    "    keras.layers.Dense(1, activation='elu')\n",
    "])\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,\n",
    "                                               min_delta=1e-4)\n",
    "\n",
    "conv_model.compile(optimizer='adam', loss='mse')\n",
    "conv_model.fit(X_train, y_train, epochs=60, batch_size=128,\n",
    "               callbacks=[early_stopping],\n",
    "               validation_data=(X_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5070\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5069503784179688"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.7446950226284034, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.697776868966826, gpu_id=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.11205606010503663, max_bin=538,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=9, max_leaves=None,\n             min_child_weight=2.1057925465153993, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=None, ...)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.7446950226284034, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.697776868966826, gpu_id=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.11205606010503663, max_bin=538,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=9, max_leaves=None,\n             min_child_weight=2.1057925465153993, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.7446950226284034, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.697776868966826, gpu_id=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.11205606010503663, max_bin=538,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=9, max_leaves=None,\n             min_child_weight=2.1057925465153993, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "split = int(train_raw.shape[0] * .7)\n",
    "X_train_xgb = train_raw[:split, :14]\n",
    "y_train_xgb = train_raw[:split, 14:]\n",
    "\n",
    "\n",
    "regressor = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.7446950226284034,\n",
    "    gamma=0.697776868966826,\n",
    "    learning_rate=0.11205606010503663,\n",
    "    max_bin=538,\n",
    "    max_depth=9,\n",
    "    min_child_weight=2.1057925465153993)\n",
    "\n",
    "regressor.fit(X_train_xgb, y_train_xgb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 15s 9ms/step - loss: 1.9210 - val_loss: 0.5535\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5540 - val_loss: 0.6002\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5455 - val_loss: 0.5358\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5437 - val_loss: 0.5391\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5420 - val_loss: 0.5332\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5403 - val_loss: 0.5317\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5384 - val_loss: 0.5313\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5359 - val_loss: 0.5273\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.5337 - val_loss: 0.5252\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5321 - val_loss: 0.5266\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5311 - val_loss: 0.5250\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5297 - val_loss: 0.5237\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5289 - val_loss: 0.5218\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5276 - val_loss: 0.5206\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5265 - val_loss: 0.5210\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5255 - val_loss: 0.5197\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5238 - val_loss: 0.5210\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5233 - val_loss: 0.5168\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5220 - val_loss: 0.5189\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5209 - val_loss: 0.5144\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.5202 - val_loss: 0.5138\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5196 - val_loss: 0.5132\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5186 - val_loss: 0.5144\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5181 - val_loss: 0.5123\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5170 - val_loss: 0.5134\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.5163 - val_loss: 0.5131\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5155 - val_loss: 0.5113\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5149 - val_loss: 0.5100\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5143 - val_loss: 0.5102\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5141 - val_loss: 0.5093\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5136 - val_loss: 0.5106\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5131 - val_loss: 0.5101\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5129 - val_loss: 0.5089\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.5125 - val_loss: 0.5080\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5119 - val_loss: 0.5099\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5116 - val_loss: 0.5098\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5110 - val_loss: 0.5083\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5107 - val_loss: 0.5077\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5102 - val_loss: 0.5080\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5099 - val_loss: 0.5089\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5100 - val_loss: 0.5070\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5094 - val_loss: 0.5067\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5093 - val_loss: 0.5103\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5088 - val_loss: 0.5063\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5084 - val_loss: 0.5070\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5079 - val_loss: 0.5066\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5079 - val_loss: 0.5079\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5072 - val_loss: 0.5079\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.5068 - val_loss: 0.5068\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5067 - val_loss: 0.5078\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5064 - val_loss: 0.5069\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5060 - val_loss: 0.5085\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5056 - val_loss: 0.5108\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.5056 - val_loss: 0.5064\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x23dfa8add90>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model = keras.models.Sequential([\n",
    "    keras.layers.GRU(30, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    keras.layers.GRU(30),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(32, activation='elu'),\n",
    "    keras.layers.Dense(1, activation='elu')\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='mse')\n",
    "rnn_model.fit(X_train, y_train, epochs=200, batch_size=128,\n",
    "              callbacks=[early_stopping],\n",
    "              validation_data=(X_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\rnn_baseline\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models\\rnn_baseline\\assets\n"
     ]
    }
   ],
   "source": [
    "rnn_model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def predict_ensemble(test_raw: np.array) -> np.array:\n",
    "    nn_test = test_raw.reshape(test_raw.shape[0], test_raw.shape[1], 1)\n",
    "\n",
    "    conv_predictions = conv_model.predict(nn_test)\n",
    "    rnn_predictions = rnn_model.predict(nn_test)\n",
    "    xgb_predictions = regressor.predict(test_raw)\n",
    "    stacked_predictions = np.column_stack((conv_predictions, rnn_predictions, xgb_predictions))\n",
    "    target = np.mean(stacked_predictions, axis=1)\n",
    "\n",
    "    return target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def prepare_for_rnn(data, n_in=1, n_out=1):\n",
    "    n_vars = data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = [], []\n",
    "\n",
    "    for i in range(n_in, 0, -1):\n",
    "        shifted = df.shift(i).fillna(0)\n",
    "\n",
    "        cols.append(shifted)\n",
    "\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\n",
    "    for i in range(0, n_out):\n",
    "        shifted = df.shift(-i).fillna(0)\n",
    "\n",
    "        cols.append(shifted)\n",
    "\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "train_rnn = prepare_for_rnn(train_raw, 1, 20)\n",
    "values = train_rnn.values\n",
    "train_rnn = values[:split, :]\n",
    "valid_rnn = values[split:, :]\n",
    "X_train_rnn, y_train_rnn = train_rnn[:, :-1], train_rnn[:, -1]\n",
    "X_valid_rnn, y_valid_rnn = valid_rnn[:, :-1], valid_rnn[:, -1]\n",
    "X_train_rnn = X_train_rnn.reshape((X_train_rnn.shape[0], 1, X_train_rnn.shape[1]))\n",
    "X_valid_rnn = X_valid_rnn.reshape((X_valid_rnn.shape[0], 1, X_valid_rnn.shape[1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1407/1407 [==============================] - 17s 11ms/step - loss: 1.1432 - val_loss: 0.5567\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5690 - val_loss: 0.5513\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5496 - val_loss: 0.5630\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5433 - val_loss: 0.5328\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5404 - val_loss: 0.5304\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5371 - val_loss: 0.5291\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5339 - val_loss: 0.5262\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5314 - val_loss: 0.5265\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5298 - val_loss: 0.5273\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5276 - val_loss: 0.5212\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5258 - val_loss: 0.5191\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5240 - val_loss: 0.5173\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5223 - val_loss: 0.5151\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5210 - val_loss: 0.5176\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5190 - val_loss: 0.5122\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 0.5179 - val_loss: 0.5117\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5165 - val_loss: 0.5117\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5155 - val_loss: 0.5103\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5145 - val_loss: 0.5113\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5138 - val_loss: 0.5090\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5130 - val_loss: 0.5089\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5122 - val_loss: 0.5072\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5112 - val_loss: 0.5088\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5104 - val_loss: 0.5075\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5093 - val_loss: 0.5073\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5087 - val_loss: 0.5076\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5075 - val_loss: 0.5059\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5073 - val_loss: 0.5068\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5064 - val_loss: 0.5066\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5056 - val_loss: 0.5078\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5047 - val_loss: 0.5080\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5038 - val_loss: 0.5053\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5027 - val_loss: 0.5073\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5024 - val_loss: 0.5055\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5022 - val_loss: 0.5053\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5004 - val_loss: 0.5072\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5002 - val_loss: 0.5084\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4989 - val_loss: 0.5060\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4981 - val_loss: 0.5101\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4972 - val_loss: 0.5091\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4968 - val_loss: 0.5076\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4959 - val_loss: 0.5089\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4946 - val_loss: 0.5104\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4943 - val_loss: 0.5107\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4931 - val_loss: 0.5082\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4937 - val_loss: 0.5098\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4956 - val_loss: 0.5084\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4901 - val_loss: 0.5122\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4894 - val_loss: 0.5075\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.4885 - val_loss: 0.5097\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.4884 - val_loss: 0.5105\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.4871 - val_loss: 0.5129\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x240ebcee220>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model_diff_data = keras.models.Sequential([\n",
    "    keras.layers.GRU(100, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.GRU(100),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(32, activation='elu'),\n",
    "    keras.layers.Dense(1, activation='elu')\n",
    "])\n",
    "early_stopping_rnn = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                                   min_delta=1e-4)\n",
    "\n",
    "rnn_model_diff_data.compile(optimizer='adam', loss='mse')\n",
    "rnn_model_diff_data.fit(X_train, y_train, epochs=200, batch_size=128,\n",
    "              callbacks=[early_stopping_rnn],\n",
    "              validation_data=(X_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 7s 1ms/step\n",
      "6250/6250 [==============================] - 16s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_target = predict_ensemble(test_raw.drop('id', axis=1).to_numpy())\n",
    "\n",
    "pd\\\n",
    "    .DataFrame(np.column_stack([test_raw.loc[:, 'id'], y_target]), columns=['id', 'target'])\\\n",
    "    .astype({'id': int})\\\n",
    "    .to_csv(os.path.join('submissions', 'ensemble.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
