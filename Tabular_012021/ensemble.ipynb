{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This went quite well - got 0.6995 on private score, 0.70083 on the public one. It probably could be tweaked as the neural network at the end does the difference. The other competitors mentioned scaling the target variable to [0-1] range and were saying it allowed them to go down a bit with their MSE, but given that this task got me tired as no other, for now I'm leaving the solution as is."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('data/train.csv')\n",
    "train_ids = train_full[['id']].to_numpy(dtype=int)\n",
    "xs = train_full.drop('id', axis=1).to_numpy()\n",
    "ys = train_full[['target']].to_numpy()\n",
    "test_full = pd.read_csv('data/test.csv')\n",
    "ids_test = test_full[['id']].to_numpy(dtype=int)\n",
    "test = test_full.drop('id', axis=1).to_numpy()\n",
    "split = int(xs.shape[0] * .8)\n",
    "X_train = xs[:split, :-1]\n",
    "y_train = ys[:split, -1]\n",
    "ids_train = train_ids[:split, 0]\n",
    "X_valid = xs[split:, :-1]\n",
    "y_valid = ys[split:, -1]\n",
    "ids_valid = train_ids[split:, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class SwapNoise(keras.layers.Layer):\n",
    "    def __init__(self, ratio=0.15, col_to_apply=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "        self.col_to_apply = col_to_apply\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            noisy_inputs = tf.map_fn(lambda x: SwapNoise._add_swap_noise(x, ratio=self.ratio, col_to_apply=self.col_to_apply), inputs)\n",
    "            return noisy_inputs\n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_swap_noise(X, ratio=.15, col_to_apply=None, return_mask=False):\n",
    "        if col_to_apply is None:\n",
    "            col_to_apply = []\n",
    "\n",
    "        shape = tf.shape(X)\n",
    "        obfuscation_mask = tf.cast(\n",
    "            tf.random.stateless_binomial(\n",
    "                shape=shape,\n",
    "                seed=(1, 2),\n",
    "                counts=1,\n",
    "                probs=tf.fill(shape, ratio)),\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        if col_to_apply:\n",
    "            column_mask = np.zeros(X.shape, dtype=np.float32)\n",
    "            column_mask[col_to_apply] = 1\n",
    "            obfuscation_mask *= column_mask\n",
    "\n",
    "        shuffled_rows = tf.random.shuffle(tf.range(tf.shape(X)[0]))\n",
    "        obfuscated_X = tf.where(obfuscation_mask == 1, tf.gather(X, shuffled_rows), X)\n",
    "\n",
    "        if return_mask:\n",
    "            return obfuscated_X, obfuscation_mask\n",
    "\n",
    "        return obfuscated_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.8305INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae1\\assets\n",
      "3750/3750 [==============================] - 112s 29ms/step - loss: 0.8305 - val_loss: 0.5604\n",
      "Epoch 2/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5827INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae2\\assets\n",
      "3750/3750 [==============================] - 107s 28ms/step - loss: 0.5827 - val_loss: 0.5242\n",
      "Epoch 3/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5691INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae3\\assets\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5691 - val_loss: 0.5216\n",
      "Epoch 4/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5588 - val_loss: 0.5327\n",
      "Epoch 5/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5532 - val_loss: 0.5325\n",
      "Epoch 6/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5498INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae6\\assets\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5498 - val_loss: 0.5184\n",
      "Epoch 7/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5495 - val_loss: 0.5327\n",
      "Epoch 8/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5480 - val_loss: 0.5260\n",
      "Epoch 9/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5450 - val_loss: 0.5210\n",
      "Epoch 10/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5444INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae10\\assets\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5444 - val_loss: 0.5158\n",
      "Epoch 11/300\n",
      "3750/3750 [==============================] - 107s 28ms/step - loss: 0.5443 - val_loss: 0.5161\n",
      "Epoch 12/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5427INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae12\\assets\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5427 - val_loss: 0.5155\n",
      "Epoch 13/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5413 - val_loss: 0.5241\n",
      "Epoch 14/300\n",
      "3750/3750 [==============================] - 103s 28ms/step - loss: 0.5404 - val_loss: 0.5159\n",
      "Epoch 15/300\n",
      "3750/3750 [==============================] - 93s 25ms/step - loss: 0.5397 - val_loss: 0.5159\n",
      "Epoch 16/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5387INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae16\\assets\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5387 - val_loss: 0.5150\n",
      "Epoch 17/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5387 - val_loss: 0.5247\n",
      "Epoch 18/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5378 - val_loss: 0.5172\n",
      "Epoch 19/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5375 - val_loss: 0.5169\n",
      "Epoch 20/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5363INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae20\\assets\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5363 - val_loss: 0.5133\n",
      "Epoch 21/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5353 - val_loss: 0.5177\n",
      "Epoch 22/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5350 - val_loss: 0.5145\n",
      "Epoch 23/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5341 - val_loss: 0.5164\n",
      "Epoch 24/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5340 - val_loss: 0.5168\n",
      "Epoch 25/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5333 - val_loss: 0.5137\n",
      "Epoch 26/300\n",
      "3750/3750 [==============================] - 93s 25ms/step - loss: 0.5326 - val_loss: 0.5160\n",
      "Epoch 27/300\n",
      "3750/3750 [==============================] - 94s 25ms/step - loss: 0.5323 - val_loss: 0.5136\n",
      "Epoch 28/300\n",
      "3750/3750 [==============================] - 93s 25ms/step - loss: 0.5311 - val_loss: 0.5174\n",
      "Epoch 29/300\n",
      "3750/3750 [==============================] - 94s 25ms/step - loss: 0.5313 - val_loss: 0.5179\n",
      "Epoch 30/300\n",
      "3750/3750 [==============================] - 95s 25ms/step - loss: 0.5310 - val_loss: 0.5149\n",
      "Epoch 31/300\n",
      "3750/3750 [==============================] - 94s 25ms/step - loss: 0.5298 - val_loss: 0.5137\n",
      "Epoch 32/300\n",
      "3750/3750 [==============================] - 94s 25ms/step - loss: 0.5290 - val_loss: 0.5181\n",
      "Epoch 33/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5290 - val_loss: 0.5185\n",
      "Epoch 34/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5279 - val_loss: 0.5133\n",
      "Epoch 35/300\n",
      "3750/3750 [==============================] - 107s 28ms/step - loss: 0.5278 - val_loss: 0.5203\n",
      "Epoch 36/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5273 - val_loss: 0.5200\n",
      "Epoch 37/300\n",
      "3750/3750 [==============================] - 93s 25ms/step - loss: 0.5270 - val_loss: 0.5140\n",
      "Epoch 38/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5272 - val_loss: 0.5148\n",
      "Epoch 39/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5262INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae39\\assets\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5262 - val_loss: 0.5105\n",
      "Epoch 40/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5261 - val_loss: 0.5146\n",
      "Epoch 41/300\n",
      "3750/3750 [==============================] - 111s 29ms/step - loss: 0.5253 - val_loss: 0.5127\n",
      "Epoch 42/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5261 - val_loss: 0.5131\n",
      "Epoch 43/300\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5244 - val_loss: 0.5164\n",
      "Epoch 44/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5249 - val_loss: 0.5113\n",
      "Epoch 45/300\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5243 - val_loss: 0.5118\n",
      "Epoch 46/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5239 - val_loss: 0.5142\n",
      "Epoch 47/300\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5236 - val_loss: 0.5151\n",
      "Epoch 48/300\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5237 - val_loss: 0.5121\n",
      "Epoch 49/300\n",
      "3750/3750 [==============================] - 115s 31ms/step - loss: 0.5229 - val_loss: 0.5210\n",
      "Epoch 50/300\n",
      "3750/3750 [==============================] - 112s 30ms/step - loss: 0.5225 - val_loss: 0.5128\n",
      "Epoch 51/300\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5226 - val_loss: 0.5125\n",
      "Epoch 52/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5226 - val_loss: 0.5146\n",
      "Epoch 53/300\n",
      "3750/3750 [==============================] - 115s 31ms/step - loss: 0.5217 - val_loss: 0.5127\n",
      "Epoch 54/300\n",
      "3750/3750 [==============================] - 113s 30ms/step - loss: 0.5211 - val_loss: 0.5110\n",
      "Epoch 55/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5220 - val_loss: 0.5108\n",
      "Epoch 56/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5212 - val_loss: 0.5127\n",
      "Epoch 57/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5213 - val_loss: 0.5106\n",
      "Epoch 58/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5207 - val_loss: 0.5128\n",
      "Epoch 59/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5202INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae59\\assets\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5202 - val_loss: 0.5089\n",
      "Epoch 60/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5206 - val_loss: 0.5113\n",
      "Epoch 61/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5199 - val_loss: 0.5110\n",
      "Epoch 62/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5197 - val_loss: 0.5150\n",
      "Epoch 63/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5197 - val_loss: 0.5121\n",
      "Epoch 64/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5198 - val_loss: 0.5134\n",
      "Epoch 65/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5199 - val_loss: 0.5116\n",
      "Epoch 66/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5192 - val_loss: 0.5098\n",
      "Epoch 67/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5184 - val_loss: 0.5125\n",
      "Epoch 68/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5180 - val_loss: 0.5128\n",
      "Epoch 69/300\n",
      "3750/3750 [==============================] - 98s 26ms/step - loss: 0.5184 - val_loss: 0.5115\n",
      "Epoch 70/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5182 - val_loss: 0.5166\n",
      "Epoch 71/300\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5180 - val_loss: 0.5091\n",
      "Epoch 72/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5174 - val_loss: 0.5154\n",
      "Epoch 73/300\n",
      "3750/3750 [==============================] - 98s 26ms/step - loss: 0.5172 - val_loss: 0.5108\n",
      "Epoch 74/300\n",
      "3750/3750 [==============================] - 103s 28ms/step - loss: 0.5169 - val_loss: 0.5143\n",
      "Epoch 75/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5171INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae75\\assets\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5171 - val_loss: 0.5087\n",
      "Epoch 76/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5171 - val_loss: 0.5089\n",
      "Epoch 77/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5165 - val_loss: 0.5100\n",
      "Epoch 78/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5162 - val_loss: 0.5218\n",
      "Epoch 79/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5162 - val_loss: 0.5137\n",
      "Epoch 80/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5153 - val_loss: 0.5110\n",
      "Epoch 81/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5158 - val_loss: 0.5096\n",
      "Epoch 82/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5154 - val_loss: 0.5106\n",
      "Epoch 83/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5151INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae83\\assets\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5151 - val_loss: 0.5085\n",
      "Epoch 84/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5148 - val_loss: 0.5092\n",
      "Epoch 85/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5146INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae85\\assets\n",
      "3750/3750 [==============================] - 111s 29ms/step - loss: 0.5147 - val_loss: 0.5084\n",
      "Epoch 86/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5146 - val_loss: 0.5084\n",
      "Epoch 87/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5147 - val_loss: 0.5105\n",
      "Epoch 88/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5143INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae88\\assets\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5143 - val_loss: 0.5083\n",
      "Epoch 89/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5140 - val_loss: 0.5100\n",
      "Epoch 90/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5137 - val_loss: 0.5130\n",
      "Epoch 91/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5138 - val_loss: 0.5093\n",
      "Epoch 92/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5137 - val_loss: 0.5085\n",
      "Epoch 93/300\n",
      "3748/3750 [============================>.] - ETA: 0s - loss: 0.5131INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae93\\assets\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5132 - val_loss: 0.5081\n",
      "Epoch 94/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5134 - val_loss: 0.5102\n",
      "Epoch 95/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5130 - val_loss: 0.5108\n",
      "Epoch 96/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5126INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae96\\assets\n",
      "3750/3750 [==============================] - 107s 28ms/step - loss: 0.5126 - val_loss: 0.5075\n",
      "Epoch 97/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5126 - val_loss: 0.5096\n",
      "Epoch 98/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5126 - val_loss: 0.5082\n",
      "Epoch 99/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5125 - val_loss: 0.5090\n",
      "Epoch 100/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5125 - val_loss: 0.5096\n",
      "Epoch 101/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5122 - val_loss: 0.5076\n",
      "Epoch 102/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5122INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae102\\assets\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5122 - val_loss: 0.5072\n",
      "Epoch 103/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5119 - val_loss: 0.5086\n",
      "Epoch 104/300\n",
      "3750/3750 [==============================] - 107s 28ms/step - loss: 0.5118 - val_loss: 0.5084\n",
      "Epoch 105/300\n",
      "3750/3750 [==============================] - 109s 29ms/step - loss: 0.5117 - val_loss: 0.5089\n",
      "Epoch 106/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5120 - val_loss: 0.5088\n",
      "Epoch 107/300\n",
      "3750/3750 [==============================] - 99s 26ms/step - loss: 0.5120 - val_loss: 0.5090\n",
      "Epoch 108/300\n",
      "3750/3750 [==============================] - 99s 26ms/step - loss: 0.5120 - val_loss: 0.5081\n",
      "Epoch 109/300\n",
      "3750/3750 [==============================] - 98s 26ms/step - loss: 0.5115 - val_loss: 0.5088\n",
      "Epoch 110/300\n",
      "3750/3750 [==============================] - 98s 26ms/step - loss: 0.5118 - val_loss: 0.5084\n",
      "Epoch 111/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5121 - val_loss: 0.5082\n",
      "Epoch 112/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5116 - val_loss: 0.5084\n",
      "Epoch 113/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5112INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae113\\assets\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5112 - val_loss: 0.5072\n",
      "Epoch 114/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5111 - val_loss: 0.5088\n",
      "Epoch 115/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5116 - val_loss: 0.5073\n",
      "Epoch 116/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5115 - val_loss: 0.5089\n",
      "Epoch 117/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5113 - val_loss: 0.5079\n",
      "Epoch 118/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5108 - val_loss: 0.5093\n",
      "Epoch 119/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5111 - val_loss: 0.5088\n",
      "Epoch 120/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5111INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae120\\assets\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5111 - val_loss: 0.5068\n",
      "Epoch 121/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5112 - val_loss: 0.5089\n",
      "Epoch 122/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5108 - val_loss: 0.5074\n",
      "Epoch 123/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5112 - val_loss: 0.5074\n",
      "Epoch 124/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5107 - val_loss: 0.5085\n",
      "Epoch 125/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5109 - val_loss: 0.5085\n",
      "Epoch 126/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5106 - val_loss: 0.5116\n",
      "Epoch 127/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5105 - val_loss: 0.5076\n",
      "Epoch 128/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5105 - val_loss: 0.5073\n",
      "Epoch 129/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5106INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae129\\assets\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5105 - val_loss: 0.5066\n",
      "Epoch 130/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5103 - val_loss: 0.5086\n",
      "Epoch 131/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5104 - val_loss: 0.5086\n",
      "Epoch 132/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5104 - val_loss: 0.5078\n",
      "Epoch 133/300\n",
      "3750/3750 [==============================] - 98s 26ms/step - loss: 0.5100 - val_loss: 0.5100\n",
      "Epoch 134/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5102 - val_loss: 0.5073\n",
      "Epoch 135/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5101 - val_loss: 0.5078\n",
      "Epoch 136/300\n",
      "3748/3750 [============================>.] - ETA: 0s - loss: 0.5106INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae136\\assets\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5105 - val_loss: 0.5060\n",
      "Epoch 137/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5097 - val_loss: 0.5080\n",
      "Epoch 138/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5103 - val_loss: 0.5065\n",
      "Epoch 139/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5099 - val_loss: 0.5070\n",
      "Epoch 140/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5101 - val_loss: 0.5076\n",
      "Epoch 141/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5100 - val_loss: 0.5105\n",
      "Epoch 142/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5101 - val_loss: 0.5092\n",
      "Epoch 143/300\n",
      "3750/3750 [==============================] - 107s 28ms/step - loss: 0.5099 - val_loss: 0.5073\n",
      "Epoch 144/300\n",
      "3750/3750 [==============================] - 111s 30ms/step - loss: 0.5096 - val_loss: 0.5066\n",
      "Epoch 145/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5095 - val_loss: 0.5070\n",
      "Epoch 146/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5094 - val_loss: 0.5085\n",
      "Epoch 147/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5094 - val_loss: 0.5069\n",
      "Epoch 148/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5093 - val_loss: 0.5072\n",
      "Epoch 149/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5096 - val_loss: 0.5081\n",
      "Epoch 150/300\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.5092 - val_loss: 0.5077\n",
      "Epoch 151/300\n",
      "3750/3750 [==============================] - 112s 30ms/step - loss: 0.5093 - val_loss: 0.5079\n",
      "Epoch 152/300\n",
      "3750/3750 [==============================] - 108s 29ms/step - loss: 0.5092 - val_loss: 0.5090\n",
      "Epoch 153/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5090 - val_loss: 0.5074\n",
      "Epoch 154/300\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.5091 - val_loss: 0.5064\n",
      "Epoch 155/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5090 - val_loss: 0.5066\n",
      "Epoch 156/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5085 - val_loss: 0.5062\n",
      "Epoch 157/300\n",
      "3750/3750 [==============================] - 103s 27ms/step - loss: 0.5089 - val_loss: 0.5086\n",
      "Epoch 158/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5089 - val_loss: 0.5075\n",
      "Epoch 159/300\n",
      "3750/3750 [==============================] - 103s 28ms/step - loss: 0.5086 - val_loss: 0.5069\n",
      "Epoch 160/300\n",
      "3750/3750 [==============================] - 101s 27ms/step - loss: 0.5085 - val_loss: 0.5068\n",
      "Epoch 161/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5086 - val_loss: 0.5075\n",
      "Epoch 162/300\n",
      "3750/3750 [==============================] - 102s 27ms/step - loss: 0.5091 - val_loss: 0.5077\n",
      "Epoch 163/300\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.5088 - val_loss: 0.5067\n",
      "Epoch 164/300\n",
      "3750/3750 [==============================] - 107s 28ms/step - loss: 0.5086 - val_loss: 0.5097\n",
      "Epoch 165/300\n",
      "3750/3750 [==============================] - 105s 28ms/step - loss: 0.5084 - val_loss: 0.5078\n",
      "Epoch 166/300\n",
      "3750/3750 [==============================] - 106s 28ms/step - loss: 0.5085 - val_loss: 0.5093\n"
     ]
    }
   ],
   "source": [
    "regressor = keras.Sequential([\n",
    "    SwapNoise(ratio=.1),\n",
    "    keras.layers.Dense(256),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.1),\n",
    "    keras.layers.Dense(256),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.1),\n",
    "    keras.layers.Dense(256),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.1),\n",
    "    keras.layers.Dense(256),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.1),\n",
    "    keras.layers.Dense(1),\n",
    "    keras.layers.PReLU()\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30,\n",
    "                                               min_delta=1e-6)\n",
    "regressor.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = regressor.fit(X_train, y_train, epochs=300, batch_size=64,\n",
    "           callbacks=[\n",
    "               early_stopping,\n",
    "               keras.callbacks.ModelCheckpoint(\n",
    "                   filepath='saved_models/dnn_regressor_after_dae{epoch}',\n",
    "                   save_best_only=True)],\n",
    "           validation_data=(X_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse._csr import csr_matrix\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from typing import Callable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def rte_objective(search_space: dict) -> dict:\n",
    "    rte = RandomTreesEmbedding(**search_space)\n",
    "    ridge = Ridge(alpha=3000)\n",
    "\n",
    "    rte.fit(X_train)\n",
    "\n",
    "    X_train_transformed = rte.transform(X_train)\n",
    "\n",
    "    ridge.fit(X_train_transformed, y_train)\n",
    "\n",
    "    X_valid_transformed = rte.transform(X_valid)\n",
    "    y_pred = ridge.predict(X_valid_transformed)\n",
    "    accuracy = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "    return {'loss': accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def find_params(search_space: dict, get_objective: Callable) -> dict:\n",
    "    algorithm = tpe.suggest\n",
    "    best_params = fmin(\n",
    "        fn=get_objective,\n",
    "        space=search_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=100)\n",
    "\n",
    "    return best_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [3:32:32<00:00, 127.52s/trial, best loss: 0.4892925067882283] \n"
     ]
    }
   ],
   "source": [
    "rte_params = find_params({\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 2000, 50)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 10, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 50, 200, 50)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 25, 200, 25)),\n",
    "    'n_jobs': -2}, rte_objective)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def xgb_objective(search_space: dict) -> dict:\n",
    "    regressor = xgb.XGBRegressor(**search_space)\n",
    "\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = regressor.predict(X_valid)\n",
    "    accuracy = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "    return {'loss': accuracy, 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [21:08<00:00, 12.69s/trial, best loss: 0.48856797903425425]\n"
     ]
    }
   ],
   "source": [
    "xgb_params = find_params({\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'gamma': hp.uniform ('gamma', 0, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0, 1),\n",
    "    'min_child_weight' : hp.uniform('min_child_weight', 0, 5),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0, .15),\n",
    "    'random_state': 5,\n",
    "    'max_bin' : scope.int(hp.quniform('max_bin', 200, 550, 1))}, xgb_objective)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.838418115820081, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.34980482863950296, gpu_id=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.07097890845615876, max_bin=367,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=10, max_leaves=None,\n             min_child_weight=1.0019995276220504, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=None, ...)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.838418115820081, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.34980482863950296, gpu_id=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.07097890845615876, max_bin=367,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=10, max_leaves=None,\n             min_child_weight=1.0019995276220504, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.838418115820081, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.34980482863950296, gpu_id=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.07097890845615876, max_bin=367,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=10, max_leaves=None,\n             min_child_weight=1.0019995276220504, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.838418115820081,\n",
    "    gamma=0.34980482863950296,\n",
    "    learning_rate=0.07097890845615876,\n",
    "    max_bin=367,\n",
    "    max_depth=10,\n",
    "    min_child_weight=1.0019995276220504)\n",
    "\n",
    "regressor.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Ridge(alpha=3000)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=3000)</pre></div></div></div></div></div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte = RandomTreesEmbedding(max_depth=5, min_samples_leaf=100, min_samples_split=200, n_estimators=1000)\n",
    "ridge = Ridge(alpha=3000)\n",
    "\n",
    "rte.fit(X_train)\n",
    "\n",
    "X_train_transformed = rte.transform(X_train)\n",
    "X_valid_transformed = rte.transform(X_valid)\n",
    "\n",
    "ridge.fit(X_train_transformed, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_file(name: str, xs_trans: csr_matrix, xs_old: np.ndarray, ids: np.ndarray, ys: np.ndarray = None):\n",
    "    col_names = \\\n",
    "        ['id'] +\\\n",
    "        [f'cat{idx}' for idx in range(xs_trans.shape[1])] +\\\n",
    "        [f'cont{idx}' for idx in range(xs_old.shape[1])]\n",
    "\n",
    "    if ys is not None:\n",
    "        col_names += ['target']\n",
    "\n",
    "    with open(os.path.join('data', f'{name}_enhanced.csv'), 'w') as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "\n",
    "        writer.writerow(col_names)\n",
    "\n",
    "        for i in range(0, xs_trans.shape[0]):\n",
    "            enhanced_repr = xs_trans.getrow(i).toarray()[0]\n",
    "            enhanced_repr = enhanced_repr.reshape(enhanced_repr.shape[0], 1)\n",
    "            old_features = xs_old[i, :]\n",
    "            old_features = old_features.reshape(old_features.shape[0], 1)\n",
    "            tall_repr = np.vstack([enhanced_repr, old_features])\n",
    "            wide_repr = tall_repr.reshape(1, tall_repr.shape[0]).tolist()[0]\n",
    "            user_id = [ids[i, 0]] if ids.ndim == 2 else [ids[i]]\n",
    "            full_row = user_id + wide_repr + ([ys[i]] if ys is not None else [])\n",
    "\n",
    "            writer.writerow(full_row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "create_file('train', X_train_transformed, X_train, ids_train, y_train)\n",
    "create_file('valid', X_valid_transformed, X_valid, ids_valid, y_valid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_train_record_defaults():\n",
    "    zf = tf.zeros(shape=(1,), dtype=tf.float32)\n",
    "\n",
    "    # the +2 part is because of id and target\n",
    "    return [zf] * (X_train_transformed.shape[1] + X_train.shape[1] + 2)\n",
    "\n",
    "\n",
    "def parse_train_batch(tf_string: str):\n",
    "    data = tf.io.decode_csv(tf_string, get_train_record_defaults())\n",
    "    features = data[1:-1]\n",
    "    labels = data[-1]\n",
    "    features = tf.stack(features, axis=-1)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def get_train_batched_dataset(batch_size: int, data_path: str) -> tf.data.Dataset:\n",
    "    return tf.data.TextLineDataset([data_path])\\\n",
    "        .skip(1)\\\n",
    "        .batch(batch_size)\\\n",
    "        .map(parse_train_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_dataset = get_train_batched_dataset(64, os.path.join('data', 'train_enhanced.csv'))\n",
    "valid_dataset = get_train_batched_dataset(64, os.path.join('data', 'valid_enhanced.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "   3749/Unknown - 142s 37ms/step - loss: 0.8966INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae_enhanced1\\assets\n",
      "3750/3750 [==============================] - 171s 45ms/step - loss: 0.8966 - val_loss: 5.8594\n",
      "Epoch 2/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.6555INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae_enhanced2\\assets\n",
      "3750/3750 [==============================] - 174s 46ms/step - loss: 0.6555 - val_loss: 5.2708\n",
      "Epoch 3/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5992INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae_enhanced3\\assets\n",
      "3750/3750 [==============================] - 174s 46ms/step - loss: 0.5992 - val_loss: 1.2945\n",
      "Epoch 4/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5535INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae_enhanced4\\assets\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.5535 - val_loss: 0.5753\n",
      "Epoch 5/300\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.5354INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae_enhanced5\\assets\n",
      "3750/3750 [==============================] - 176s 47ms/step - loss: 0.5354 - val_loss: 0.5200\n",
      "Epoch 6/300\n",
      "3750/3750 [==============================] - 174s 46ms/step - loss: 0.5293 - val_loss: 0.5291\n",
      "Epoch 7/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5234INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae_enhanced7\\assets\n",
      "3750/3750 [==============================] - 182s 48ms/step - loss: 0.5234 - val_loss: 0.4934\n",
      "Epoch 8/300\n",
      "3750/3750 [==============================] - 176s 47ms/step - loss: 0.5186 - val_loss: 0.4963\n",
      "Epoch 9/300\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.5156 - val_loss: 0.4950\n",
      "Epoch 10/300\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.5162INFO:tensorflow:Assets written to: saved_models\\dnn_regressor_after_dae_enhanced10\\assets\n",
      "3750/3750 [==============================] - 175s 46ms/step - loss: 0.5162 - val_loss: 0.4916\n",
      "Epoch 11/300\n",
      "3750/3750 [==============================] - 173s 46ms/step - loss: 0.5037 - val_loss: 0.4961\n",
      "Epoch 12/300\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.5112 - val_loss: 0.4959\n",
      "Epoch 13/300\n",
      "3750/3750 [==============================] - 173s 46ms/step - loss: 0.5057 - val_loss: 0.4983\n",
      "Epoch 14/300\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.4935 - val_loss: 0.5024\n",
      "Epoch 15/300\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.4817 - val_loss: 0.5125\n",
      "Epoch 16/300\n",
      "3750/3750 [==============================] - 171s 46ms/step - loss: 0.4847 - val_loss: 0.5059\n",
      "Epoch 17/300\n",
      "3750/3750 [==============================] - 172s 46ms/step - loss: 0.4760 - val_loss: 0.5145\n",
      "Epoch 18/300\n",
      "3750/3750 [==============================] - 171s 46ms/step - loss: 0.4489 - val_loss: 0.5305\n",
      "Epoch 19/300\n",
      "3750/3750 [==============================] - 176s 47ms/step - loss: 0.4483 - val_loss: 0.5316\n",
      "Epoch 20/300\n",
      "3750/3750 [==============================] - 176s 47ms/step - loss: 0.4216 - val_loss: 0.5319\n",
      "Epoch 21/300\n",
      "3750/3750 [==============================] - 176s 47ms/step - loss: 0.4315 - val_loss: 0.5318\n",
      "Epoch 22/300\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.4063 - val_loss: 0.5410\n",
      "Epoch 23/300\n",
      "3750/3750 [==============================] - 178s 47ms/step - loss: 0.4587 - val_loss: 0.5391\n",
      "Epoch 24/300\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.4319 - val_loss: 0.5680\n",
      "Epoch 25/300\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.3893 - val_loss: 0.5518\n",
      "Epoch 26/300\n",
      "3750/3750 [==============================] - 178s 47ms/step - loss: 0.3466 - val_loss: 0.5602\n",
      "Epoch 27/300\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.4202 - val_loss: 0.5691\n",
      "Epoch 28/300\n",
      "3750/3750 [==============================] - 178s 47ms/step - loss: 0.5655 - val_loss: 0.6047\n",
      "Epoch 29/300\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.3349 - val_loss: 0.6459\n",
      "Epoch 30/300\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.3288 - val_loss: 0.6045\n",
      "Epoch 31/300\n",
      "3750/3750 [==============================] - 178s 48ms/step - loss: 1.1949 - val_loss: 0.5895\n",
      "Epoch 32/300\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.3114 - val_loss: 0.5998\n",
      "Epoch 33/300\n",
      "3750/3750 [==============================] - 180s 48ms/step - loss: 0.3030 - val_loss: 0.6405\n",
      "Epoch 34/300\n",
      "3750/3750 [==============================] - 178s 47ms/step - loss: 0.2784 - val_loss: 0.5895\n",
      "Epoch 35/300\n",
      "3750/3750 [==============================] - 178s 47ms/step - loss: 0.3004 - val_loss: 0.6298\n",
      "Epoch 36/300\n",
      "3750/3750 [==============================] - 178s 47ms/step - loss: 0.3011 - val_loss: 0.6849\n",
      "Epoch 37/300\n",
      "3750/3750 [==============================] - 178s 47ms/step - loss: 0.3782 - val_loss: 0.5773\n",
      "Epoch 38/300\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.2800 - val_loss: 0.5812\n",
      "Epoch 39/300\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 1.7342 - val_loss: 0.6215\n",
      "Epoch 40/300\n",
      "3750/3750 [==============================] - 183s 49ms/step - loss: 0.2790 - val_loss: 0.6006\n"
     ]
    }
   ],
   "source": [
    "regressor_enhanced = keras.Sequential([\n",
    "    SwapNoise(ratio=.1, col_to_apply=[X_train_transformed.shape[1] + idx for idx in range(X_train.shape[1])]),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(1),\n",
    "    keras.layers.PReLU()\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30,\n",
    "                                               min_delta=1e-6)\n",
    "regressor_enhanced.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history_enhanced = regressor_enhanced.fit(\n",
    "    train_dataset, epochs=300, batch_size=64,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath='saved_models/dnn_regressor_after_dae_enhanced{epoch}',\n",
    "            save_best_only=True)],\n",
    "    validation_data=valid_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "enhanced_regressor = keras.models.load_model(os.path.join('saved_models', 'dnn_regressor_after_dae_enhanced10'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_test_transformed = rte.transform(test)\n",
    "ridge_predictions = ridge.predict(X_test_transformed)\n",
    "xgb_predictions = regressor.predict(test)\n",
    "\n",
    "create_file('test', X_test_transformed, test, ids_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "\n",
    "\n",
    "def parse_test_batch(tf_string: Tensor):\n",
    "    zf = tf.zeros(shape=(1,), dtype=tf.float32)\n",
    "    defaults = [zf] * (14375 + 14 + 2)\n",
    "    data = tf.io.decode_csv(tf_string, defaults)\n",
    "    features = data[1:]\n",
    "    features = tf.stack(features, axis=-1)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_test_batched_dataset(batch_size: int, data_path: str) -> tf.data.Dataset:\n",
    "    return tf.data.TextLineDataset([data_path])\\\n",
    "        .skip(1)\\\n",
    "        .batch(batch_size)\\\n",
    "        .map(parse_test_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 83s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "test_dataset = get_test_batched_dataset(64, os.path.join('data', 'test_enhanced.csv'))\n",
    "nn_predictions = enhanced_regressor.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def vote():\n",
    "    reshaped_ridge_predictions = ridge_predictions.reshape((ridge_predictions.shape[0], 1))\n",
    "    reshaped_xgb_predictions = xgb_predictions.reshape((xgb_predictions.shape[0], 1))\n",
    "    avg = (reshaped_ridge_predictions + reshaped_xgb_predictions) / 2\n",
    "\n",
    "    pd\\\n",
    "        .DataFrame(np.column_stack([pd.read_csv('data/test.csv')[['id']], avg]), columns=['id', 'target'])\\\n",
    "        .astype({'id': int})\\\n",
    "        .to_csv(os.path.join('submissions', 'ensemble2.csv'), index=False)\n",
    "\n",
    "\n",
    "vote()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
