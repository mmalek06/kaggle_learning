{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:04:03.467652Z",
     "end_time": "2023-04-23T10:04:03.470675Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def normalize(vals: np.ndarray):\n",
    "    min_val = np.min(vals)\n",
    "    max_val = np.max(vals)\n",
    "    normalized_values = (vals - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_values\n",
    "\n",
    "\n",
    "def restore(normalized_values: np.ndarray, vals: np.ndarray):\n",
    "    original_min = np.min(vals)\n",
    "    original_max = np.max(vals)\n",
    "    normalized_values = np.array(normalized_values)\n",
    "    restored_values = normalized_values * (original_max - original_min) + original_min\n",
    "\n",
    "    return restored_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:03:56.520906Z",
     "end_time": "2023-04-23T10:03:56.525184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('data/train.csv')\n",
    "train_ids = train_full[['id']].to_numpy(dtype=int)\n",
    "xs = train_full.drop('id', axis=1).to_numpy()\n",
    "ys = train_full[['target']].to_numpy()\n",
    "test_full = pd.read_csv('data/test.csv')\n",
    "ids_test = test_full[['id']].to_numpy(dtype=int)\n",
    "test = test_full.drop('id', axis=1).to_numpy()\n",
    "split = int(xs.shape[0] * .8)\n",
    "X_train = xs[:split, :-1]\n",
    "y_train = ys[:split, -1]\n",
    "y_train_normalized = normalize(y_train)\n",
    "ids_train = train_ids[:split, 0]\n",
    "X_valid = xs[split:, :-1]\n",
    "y_valid = ys[split:, -1]\n",
    "y_valid_normalized = normalize(y_valid)\n",
    "ids_valid = train_ids[split:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:40:29.648167Z",
     "end_time": "2023-04-23T09:40:31.086596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mSwapNoise\u001B[39;00m(keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mLayer):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.15\u001B[39m, col_to_apply\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class SwapNoise(keras.layers.Layer):\n",
    "    def __init__(self, ratio=0.15, col_to_apply=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "        self.col_to_apply = col_to_apply\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            noisy_inputs = tf.map_fn(lambda x: SwapNoise._add_swap_noise(x, ratio=self.ratio, col_to_apply=self.col_to_apply), inputs)\n",
    "            return noisy_inputs\n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_swap_noise(X, ratio=.15, col_to_apply=None, return_mask=False):\n",
    "        if col_to_apply is None:\n",
    "            col_to_apply = []\n",
    "\n",
    "        shape = tf.shape(X)\n",
    "        obfuscation_mask = tf.cast(\n",
    "            tf.random.stateless_binomial(\n",
    "                shape=shape,\n",
    "                seed=(1, 2),\n",
    "                counts=1,\n",
    "                probs=tf.fill(shape, ratio)),\n",
    "            dtype=tf.float32)\n",
    "\n",
    "        if col_to_apply:\n",
    "            column_mask = np.zeros(X.shape, dtype=np.float32)\n",
    "            column_mask[col_to_apply] = 1\n",
    "            obfuscation_mask *= column_mask\n",
    "\n",
    "        shuffled_rows = tf.random.shuffle(tf.range(tf.shape(X)[0]))\n",
    "        obfuscated_X = tf.where(obfuscation_mask == 1, tf.gather(X, shuffled_rows), X)\n",
    "\n",
    "        if return_mask:\n",
    "            return obfuscated_X, obfuscation_mask\n",
    "\n",
    "        return obfuscated_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse._csr import csr_matrix\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from typing import Callable"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:25:40.030913Z",
     "end_time": "2023-04-23T09:25:40.045136Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def rte_objective(search_space: dict) -> dict:\n",
    "    rte = RandomTreesEmbedding(**search_space)\n",
    "    ridge = Ridge(alpha=3000)\n",
    "\n",
    "    rte.fit(X_train)\n",
    "\n",
    "    X_train_transformed = rte.transform(X_train)\n",
    "\n",
    "    ridge.fit(X_train_transformed, y_train_normalized)\n",
    "\n",
    "    X_valid_transformed = rte.transform(X_valid)\n",
    "    y_pred = ridge.predict(X_valid_transformed)\n",
    "    accuracy = mean_squared_error(y_valid_normalized, y_pred)\n",
    "\n",
    "    return {'loss': accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def find_params(search_space: dict, get_objective: Callable) -> dict:\n",
    "    algorithm = tpe.suggest\n",
    "    best_params = fmin(\n",
    "        fn=get_objective,\n",
    "        space=search_space,\n",
    "        algo=algorithm,\n",
    "        max_evals=100)\n",
    "\n",
    "    return best_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [6:13:15<00:00, 223.95s/trial, best loss: 0.06101286318967715] \n"
     ]
    }
   ],
   "source": [
    "rte_params = find_params({\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 2000, 50)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 10, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 50, 200, 50)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 25, 200, 25)),\n",
    "    'n_jobs': -2}, rte_objective)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def xgb_objective(search_space: dict) -> dict:\n",
    "    regressor = xgb.XGBRegressor(**search_space)\n",
    "\n",
    "    regressor.fit(X_train, y_train_normalized)\n",
    "\n",
    "    y_pred = regressor.predict(X_valid)\n",
    "    accuracy = mean_squared_error(y_valid_normalized, y_pred)\n",
    "\n",
    "    return {'loss': accuracy, 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:48<00:00,  5.88s/trial, best loss: 0.018306310110094284]\n"
     ]
    }
   ],
   "source": [
    "xgb_params = find_params({\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'gamma': hp.uniform ('gamma', 0, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0, 1),\n",
    "    'min_child_weight' : hp.uniform('min_child_weight', 0, 5),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0, .15),\n",
    "    'random_state': 5,\n",
    "    'max_bin' : scope.int(hp.quniform('max_bin', 200, 550, 1))}, xgb_objective)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m regressor \u001B[38;5;241m=\u001B[39m \u001B[43mxgb\u001B[49m\u001B[38;5;241m.\u001B[39mXGBRegressor(\n\u001B[1;32m      2\u001B[0m     colsample_bytree\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.6602379452042961\u001B[39m,\n\u001B[1;32m      3\u001B[0m     gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3229199347299238\u001B[39m,\n\u001B[1;32m      4\u001B[0m     learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0027049502919725735\u001B[39m,\n\u001B[1;32m      5\u001B[0m     max_bin\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m491\u001B[39m,\n\u001B[1;32m      6\u001B[0m     max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      7\u001B[0m     min_child_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.146234118263356\u001B[39m)\n\u001B[1;32m      9\u001B[0m regressor\u001B[38;5;241m.\u001B[39mfit(X_train, y_train_normalized)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.6602379452042961,\n",
    "    gamma=0.3229199347299238,\n",
    "    learning_rate=0.0027049502919725735,\n",
    "    max_bin=491,\n",
    "    max_depth=1,\n",
    "    min_child_weight=2.146234118263356)\n",
    "\n",
    "regressor.fit(X_train, y_train_normalized)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Ridge(alpha=3000)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=3000)</pre></div></div></div></div></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte = RandomTreesEmbedding(max_depth=9, min_samples_leaf=50, min_samples_split=50, n_estimators=1600)\n",
    "ridge = Ridge(alpha=3000)\n",
    "\n",
    "rte.fit(X_train)\n",
    "\n",
    "X_train_transformed = rte.transform(X_train)\n",
    "X_valid_transformed = rte.transform(X_valid)\n",
    "\n",
    "ridge.fit(X_train_transformed, y_train_normalized)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def create_file(name: str, xs_trans: csr_matrix, xs_old: np.ndarray, ids: np.ndarray, ys: np.ndarray = None):\n",
    "    col_names = \\\n",
    "        ['id'] +\\\n",
    "        [f'cat{idx}' for idx in range(xs_trans.shape[1])] +\\\n",
    "        [f'cont{idx}' for idx in range(xs_old.shape[1])]\n",
    "\n",
    "    if ys is not None:\n",
    "        col_names += ['target']\n",
    "\n",
    "    with open(os.path.join('data', f'{name}_enhanced.csv'), 'w') as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "\n",
    "        writer.writerow(col_names)\n",
    "\n",
    "        for i in range(0, xs_trans.shape[0]):\n",
    "            enhanced_repr = xs_trans.getrow(i).toarray()[0]\n",
    "            enhanced_repr = enhanced_repr.reshape(enhanced_repr.shape[0], 1)\n",
    "            old_features = xs_old[i, :]\n",
    "            old_features = old_features.reshape(old_features.shape[0], 1)\n",
    "            tall_repr = np.vstack([enhanced_repr, old_features])\n",
    "            wide_repr = tall_repr.reshape(1, tall_repr.shape[0]).tolist()[0]\n",
    "            user_id = [ids[i, 0]] if ids.ndim == 2 else [ids[i]]\n",
    "            full_row = user_id + wide_repr + ([ys[i]] if ys is not None else [])\n",
    "\n",
    "            writer.writerow(full_row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "create_file('train_normalized', X_train_transformed, X_train, ids_train, y_train_normalized)\n",
    "create_file('valid_normalized', X_valid_transformed, X_valid, ids_valid, y_valid_normalized)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_train_record_defaults():\n",
    "    zf = tf.zeros(shape=(1,), dtype=tf.float32)\n",
    "\n",
    "    # the +2 part is because of id and target\n",
    "    return [zf] * (X_train_transformed.shape[1] + X_train.shape[1] + 2)\n",
    "\n",
    "\n",
    "def parse_train_batch(tf_string: str):\n",
    "    data = tf.io.decode_csv(tf_string, get_train_record_defaults())\n",
    "    features = data[1:-1]\n",
    "    labels = data[-1]\n",
    "    features = tf.stack(features, axis=-1)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def get_train_batched_dataset(batch_size: int, data_path: str) -> tf.data.Dataset:\n",
    "    return tf.data.TextLineDataset([data_path])\\\n",
    "        .skip(1)\\\n",
    "        .batch(batch_size)\\\n",
    "        .map(parse_train_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_dataset = get_train_batched_dataset(64, os.path.join('data', 'train_normalized_enhanced.csv'))\n",
    "valid_dataset = get_train_batched_dataset(64, os.path.join('data', 'valid_normalized_enhanced.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "   3750/Unknown - 1522s 405ms/step - loss: 0.0145INFO:tensorflow:Assets written to: saved_models\\dnn2_regressor_after_dae_enhanced1\\assets\n",
      "3750/3750 [==============================] - 1992s 530ms/step - loss: 0.0145 - val_loss: 0.0563\n",
      "Epoch 2/300\n",
      "3750/3750 [==============================] - 2090s 557ms/step - loss: 0.0053 - val_loss: 0.0640\n",
      "Epoch 3/300\n",
      " 484/3750 [==>...........................] - ETA: 24:24 - loss: 0.0050"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 23\u001B[0m\n\u001B[0;32m     19\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m,\n\u001B[0;32m     20\u001B[0m                                                min_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-6\u001B[39m)\n\u001B[0;32m     21\u001B[0m regressor_enhanced\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 23\u001B[0m history_enhanced \u001B[38;5;241m=\u001B[39m \u001B[43mregressor_enhanced\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m        \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mModelCheckpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msaved_models/dnn2_regressor_after_dae_enhanced\u001B[39;49m\u001B[38;5;132;43;01m{epoch}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m            \u001B[49m\u001B[43msave_best_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ds\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "regressor_enhanced = keras.Sequential([\n",
    "    SwapNoise(ratio=.1, col_to_apply=[X_train_transformed.shape[1] + idx for idx in range(X_train.shape[1])]),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(1),\n",
    "    keras.layers.PReLU()\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30,\n",
    "                                               min_delta=1e-6)\n",
    "regressor_enhanced.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history_enhanced = regressor_enhanced.fit(\n",
    "    train_dataset, epochs=300, batch_size=64,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath='saved_models/dnn2_regressor_after_dae_enhanced{epoch}',\n",
    "            save_best_only=True)],\n",
    "    validation_data=valid_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enhanced_regressor = keras.models.load_model(os.path.join('saved_models', 'dnn2_regressor_after_dae_enhanced6'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_transformed = rte.transform(test)\n",
    "ridge_predictions = ridge.predict(X_test_transformed)\n",
    "xgb_predictions = regressor.predict(test)\n",
    "\n",
    "create_file('test', X_test_transformed, test, ids_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "\n",
    "\n",
    "def parse_test_batch(tf_string: Tensor):\n",
    "    zf = tf.zeros(shape=(1,), dtype=tf.float32)\n",
    "    defaults = [zf] * (14628 + 14 + 2)\n",
    "    data = tf.io.decode_csv(tf_string, defaults)\n",
    "    features = data[1:]\n",
    "    features = tf.stack(features, axis=-1)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_test_batched_dataset(batch_size: int, data_path: str) -> tf.data.Dataset:\n",
    "    return tf.data.TextLineDataset([data_path])\\\n",
    "        .skip(1)\\\n",
    "        .batch(batch_size)\\\n",
    "        .map(parse_test_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = get_test_batched_dataset(64, os.path.join('data', 'test_enhanced.csv'))\n",
    "nn_predictions = enhanced_regressor.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def vote():\n",
    "    reshaped_ridge_predictions = ridge_predictions.reshape((ridge_predictions.shape[0], 1))\n",
    "    reshaped_xgb_predictions = xgb_predictions.reshape((xgb_predictions.shape[0], 1))\n",
    "    avg = (reshaped_ridge_predictions + reshaped_xgb_predictions) / 2\n",
    "    avg_restored = restore(avg, y_train)\n",
    "\n",
    "    pd\\\n",
    "        .DataFrame(np.column_stack([pd.read_csv('data/test_enhanced.csv')[['id']], avg_restored]), columns=['id', 'target'])\\\n",
    "        .astype({'id': int})\\\n",
    "        .to_csv(os.path.join('submissions', 'ensemble3.csv'), index=False)\n",
    "\n",
    "\n",
    "vote()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
